{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ffc3fbbd-fbbb-479b-a252-8f0fc2c6346c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffc3fbbd-fbbb-479b-a252-8f0fc2c6346c",
        "outputId": "7783ea51-0ccb-4594-838c-6a294a41c731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from collections import Counter\n",
        "\n",
        "import os, pathlib, shutil, random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download IMDB Data"
      ],
      "metadata": {
        "id": "unrX5_rrzHBw"
      },
      "id": "unrX5_rrzHBw"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5155fbb1-f0f2-45c2-ba69-13baae32de7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5155fbb1-f0f2-45c2-ba69-13baae32de7e",
        "outputId": "fe9c733c-9b76-4c07-be2b-9ef676734c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  20.1M      0  0:00:03  0:00:03 --:--:-- 20.1M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1QOJJPlzEuR"
      },
      "id": "s1QOJJPlzEuR",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "acfa26e8-8606-49f9-9638-8e34da8f19ef",
      "metadata": {
        "id": "acfa26e8-8606-49f9-9638-8e34da8f19ef"
      },
      "outputs": [],
      "source": [
        "# read data\n",
        "# data = pd.read_csv('data/IMDB Dataset.csv')\n",
        "# data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18ee8f3b-02fe-431d-94d0-701f0a93fda3",
      "metadata": {
        "id": "18ee8f3b-02fe-431d-94d0-701f0a93fda3"
      },
      "source": [
        "## Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228d43fd-e39a-4402-9783-ff41ea9edda2",
      "metadata": {
        "id": "228d43fd-e39a-4402-9783-ff41ea9edda2"
      },
      "source": [
        "### Creating and organizing files in folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bb6e04cc-fc13-44a2-8d5f-a9836a046248",
      "metadata": {
        "id": "bb6e04cc-fc13-44a2-8d5f-a9836a046248"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e289f41-5559-49ed-930b-e386d4a6b7f2",
      "metadata": {
        "id": "9e289f41-5559-49ed-930b-e386d4a6b7f2"
      },
      "source": [
        "### Load train, validation and test datasets from folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "73656316-4a36-4bbd-8c2d-40357a71a991",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73656316-4a36-4bbd-8c2d-40357a71a991",
        "outputId": "696759d2-797d-4259-9056-78a900ea8899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "3a477b34-8726-40d2-a2b9-43f3b30a57b8",
      "metadata": {
        "id": "3a477b34-8726-40d2-a2b9-43f3b30a57b8"
      },
      "outputs": [],
      "source": [
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "089c7d01-ee79-4d5f-9a85-a10ae770758d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "089c7d01-ee79-4d5f-9a85-a10ae770758d",
        "outputId": "766506ee-236f-4493-ab3b-87aaa1903c20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review : tf.Tensor(b'I found this movie hilarious. The spoofs on other popular movies of that time were some of the funniest I have seen in this sort of movie. Give it a try. If you saw the movies that this movie is spoofing, and you get the humor, you should enjoy the movie.<br /><br />I (and the others who watched the movie with me) felt the funniest part in the movie (this is not a spoiler because I will NOT tell you what actually happens) was a scene with the \"flashy thingy\" from MIB. When they first discover the device and do not know what it is does... and then again later in the movie... you\\'ll understand when you get there.<br /><br />My only complaint about the movie is that I have never been able to find it in DVD so that I could buy a copy.', shape=(), dtype=string)\n",
            "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "Review : tf.Tensor(b\"The Sensuous Nurse (1975) was a Italian sexual comedy that starred the one time Bond girl Ursula Andress. Man was she hot in this movie.. She was stacked and built like a *@#% brick house. Ursula was smoking hot in this movie. I have never seen a nurse's outfit that filled out before. <br /><br />Ms. Andress stars as a nurse who is hired to take care of a rich elderly man. Even one in the house seems to be knocking the boots. One night, the nurse decides to take the grandson's temperature and give some needed T.L.C. to her ancient client. The old man takes to his nurse and this angers the rest of the family. What kind of job did the family hire her out to do? Will the geezer fall for her car giver? How can she deal with the octogenarian crone and the rest of the family? To find out you need to find a copy of the SENSUOUS NURSE!! Italian but badly dubbed into English.<br /><br />Highly recommended.\", shape=(), dtype=string)\n",
            "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "Review : tf.Tensor(b'I have always wanted to see this because I love cheesy horror movies and with a title like this, I was sure \"The Incredible Melting Man\" would be a lot of fun.<br /><br />It really wasn\\'t. I mean, the acting was entertainingly bad, the script contained some classic bad lines and the special effects looked like someone had sneezed all over the lead actor, so I should have loved it. Unfortunately it\\'s really draggy between these highlights. I decided to watch the last half of the movie while doing my tax return. That\\'s how boring this film is.<br /><br />Nevertheless, if you love bad movies you will enjoy the dramatic exit of the Fat Nurse, and the stellar acting of the guy who plays Dr. Ted. To be fair to the poor man, he does have to deliver some amazingly inept lines with straight face - like the conversation he has with his wife on tracking down the I M Man:<br /><br />\"I\\'ll find him with a geiger counter.\" \"Is he radioactive?\" \"Just a little bit.\" <br /><br />Yes, the plot has Dr. Ted wandering about trying to find a superstrong zombie killing machine armed only with what looks like a mini-Dyson. He\\'s a brave man. Unfortunately his plan fails when he finds a big lot of goop on a tree. \"Oh god - it\\'s his ear!\" says Dr. Ted to the audience. I\\'m so glad he cleared that up. <br /><br />I realise I\\'m making this movie sound rather fun. It would be if it were only 10 minutes long, but unfortunately it goes on and on, and the Incredible Melting Dude just dangles about making a sticky mess when he should be eating more people in my opinion. I think if you were truly stoned you would probably love it, just don\\'t have pop-tarts during the movie, because the lead actor really does resemble one near the end.', shape=(), dtype=string)\n",
            "Label:  tf.Tensor(0, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "Review : tf.Tensor(b'There\\'s little to get excited about \"Dan in Real Life\". First off, the whole setup is incredibly contrived. Did you really believe that during that very long first meeting conversation at the restaurant, Marie wouldn\\'t have told Dan where she was going? And since Dan did all the talking during that conversation, why would she be so attracted to him? For that matter, I never figured out why Marie was so attracted to Dan throughout the movie. He\\'s very narcissistic and does little to convince us that he\\'s truly a good guy (for example he lies to Marie in the bookstore, ridicules his brother about his past girlfriends and tries to make Marie jealous with a \\'blind date\\'). There\\'s more contrivance such as that ridiculous scene at the bowling alley where Dan and Marie are caught making out by the whole family. Yeah like that could really happen. Dan in Real life is slow-paced, sappy and manipulative. Even chick flicks like The Jane Austen Book Club get higher marks than this predictable \"tearjerker\".', shape=(), dtype=string)\n",
            "Label:  tf.Tensor(0, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "Review : tf.Tensor(b'Arguably this is a very good \"sequel\", better than the first live action film 101 Dalmatians. It has good dogs, good actors, good jokes and all right slapstick! <br /><br />Cruella DeVil, who has had some rather major therapy, is now a lover of dogs and very kind to them. Many, including Chloe Simon, owner of one of the dogs that Cruella once tried to kill, do not believe this. Others, like Kevin Shepherd (owner of 2nd Chance Dog Shelter) believe that she has changed. <br /><br />Meanwhile, Dipstick, with his mate, have given birth to three cute dalmatian puppies! Little Dipper, Domino and Oddball...<br /><br />Starring Eric Idle as Waddlesworth (the hilarious macaw), Glenn Close as Cruella herself and Gerard Depardieu as Le Pelt (another baddie, the name should give a clue), this is a good family film with excitement and lots more!! One downfall of this film is that is has a lot of painful slapstick, but not quite as excessive as the last film. This is also funnier than the last film.<br /><br />Enjoy \"102 Dalmatians\"! :-)', shape=(), dtype=string)\n",
            "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
            "\n",
            "\n",
            "Review : tf.Tensor(b\"From everything I'd read about the movie, I was excited to support a film with a Christian theme. Everything about the movie was very unprofessionally done. Especially the writing! Without good writing a movie doesn't have a chance. The writer/director said in an interview that he didn't want to give away how the title relates to the story. Believe me, it was NO big surprise. I kept waiting for the teenage/young adult back-story to unfold, but it never did. As someone who has gone through a divorce, I was very disappointed. This movie would have been NO comfort to me when I first went through the emotional turmoil that divorce can bring to your life as a Christian!\", shape=(), dtype=string)\n",
            "Label:  tf.Tensor(0, shape=(), dtype=int32)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "for x, y in train_ds:\n",
        "    for text, label in zip(x,y):\n",
        "        counter += 1\n",
        "        print(\"Review :\", text)\n",
        "        print(\"Label: \", label)\n",
        "        print(\"\\n\")\n",
        "        if counter > 5:\n",
        "            break\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db06fdce-e9c2-46bc-97fd-057e792975d7",
      "metadata": {
        "id": "db06fdce-e9c2-46bc-97fd-057e792975d7"
      },
      "source": [
        "### Convert text data into numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "03c5a5a1-4412-4e9b-b0bb-cd99ec610991",
      "metadata": {
        "id": "03c5a5a1-4412-4e9b-b0bb-cd99ec610991"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = tf.keras.layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9e9d3a9a-0ac8-4d1b-91af-2a0ddac402d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e9d3a9a-0ac8-4d1b-91af-2a0ddac402d3",
        "outputId": "2b185908-978a-4a49-d193-594530af7123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review : tf.Tensor(\n",
            "[  10 1980   58  145    3 1940   11 1147  169  332   10  152  103   35\n",
            "   59   27  478    6  187    4  362  559  937 5693 1147    3   94    9\n",
            "    4   18   35  116    9   16 1462 6794 2878  160  538 5229 1129   18\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0], shape=(600,), dtype=int64)\n",
            "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "for x, y in int_train_ds:\n",
        "    for text, label in zip(x,y):\n",
        "        counter += 1\n",
        "        print(\"Review :\", text)\n",
        "        print(\"Label: \", label)\n",
        "        print(\"\\n\")\n",
        "        if counter >= 1:\n",
        "            break\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9accb3f-26a1-4938-8b63-accb12eb0121",
      "metadata": {
        "id": "d9accb3f-26a1-4938-8b63-accb12eb0121"
      },
      "source": [
        "### A sequence model built on one-hot encoded vector sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e270f4f8-e78f-415e-bdde-7dbcb5e76aac",
      "metadata": {
        "id": "e270f4f8-e78f-415e-bdde-7dbcb5e76aac"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Lambda(lambda x: tf.one_hot(x, depth=max_tokens)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d8e7295d-fb66-474f-94d8-c33b62d851dc",
      "metadata": {
        "id": "d8e7295d-fb66-474f-94d8-c33b62d851dc"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8e80d0a8-a932-41c5-890d-fc052d22cbab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e80d0a8-a932-41c5-890d-fc052d22cbab",
        "outputId": "f59f3b5c-0889-4455-8e4b-c9f9a9fadce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 37s 59ms/step - loss: 0.2867 - accuracy: 0.8963 - val_loss: 0.3848 - val_accuracy: 0.8630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78da56162dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STCRTt2Szvdx",
        "outputId": "a0e4c0d3-947f-4155-92f8-f15bff8a57ab"
      },
      "id": "STCRTt2Szvdx",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda (Lambda)             (None, 600, 20000)        0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                5128448   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5128513 (19.56 MB)\n",
            "Trainable params: 5128513 (19.56 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6aa9c63c-fa84-49f6-942d-bcf4eed5d70f",
      "metadata": {
        "id": "6aa9c63c-fa84-49f6-942d-bcf4eed5d70f"
      },
      "outputs": [],
      "source": [
        "## Try with embedding layer instead of one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ],
      "metadata": {
        "id": "kwl7N1SXy9br"
      },
      "id": "kwl7N1SXy9br",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Model (Embedding from scratch)"
      ],
      "metadata": {
        "id": "apRNR2uo0l5I"
      },
      "id": "apRNR2uo0l5I"
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n"
      ],
      "metadata": {
        "id": "L5VEjuU-ztSd"
      },
      "id": "L5VEjuU-ztSd",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7urzO2MG0od_"
      },
      "id": "7urzO2MG0od_",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lzaw4ac04Tb",
        "outputId": "029c6154-9ea5-48e6-86d7-ace90f20233e"
      },
      "id": "8Lzaw4ac04Tb",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "625/625 [==============================] - 103s 150ms/step - loss: 0.4366 - accuracy: 0.7940 - val_loss: 0.3233 - val_accuracy: 0.8658\n",
            "Epoch 2/2\n",
            "625/625 [==============================] - 62s 99ms/step - loss: 0.2806 - accuracy: 0.8877 - val_loss: 0.3032 - val_accuracy: 0.8766\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78da56188040>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "JwCxx1V25PPB"
      },
      "id": "JwCxx1V25PPB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use pretrained embedding instead of building from scratch"
      ],
      "metadata": {
        "id": "PRfqwRaL2iKf"
      },
      "id": "PRfqwRaL2iKf"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V75JV1S3Ydf",
        "outputId": "2b9d8335-9d6c-4ba8-ec20-4ebd6ceb9483"
      },
      "id": "9V75JV1S3Ydf",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-10 06:53:09--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-09-10 06:53:09--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-09-10 06:53:09--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 38s  \n",
            "\n",
            "2023-09-10 06:55:48 (5.19 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TuR42M807fX",
        "outputId": "67485146-2756-4578-82a7-5be395d82437"
      },
      "id": "7TuR42M807fX",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prepare Glove word Embedding matrix"
      ],
      "metadata": {
        "id": "GnbR3Gcs2rkQ"
      },
      "id": "GnbR3Gcs2rkQ"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "Lj3aXPO_2wSd"
      },
      "id": "Lj3aXPO_2wSd",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ],
      "metadata": {
        "id": "kF-bs3xh25eX"
      },
      "id": "kF-bs3xh25eX",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Model with pretrained Embedding"
      ],
      "metadata": {
        "id": "un2iDsTF3H-Q"
      },
      "id": "un2iDsTF3H-Q"
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    embedding_layer,\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "rlEmh2Mq3HRK"
      },
      "id": "rlEmh2Mq3HRK",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "0b3rBL-44W4Q"
      },
      "id": "0b3rBL-44W4Q",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnt8FEoW4bXO",
        "outputId": "2d05f661-3c03-4ec2-d2a7-2442497c9cb0"
      },
      "id": "gnt8FEoW4bXO",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 42s 53ms/step - loss: 0.5705 - accuracy: 0.6996 - val_loss: 0.4934 - val_accuracy: 0.7740\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.4603 - accuracy: 0.7897 - val_loss: 0.4053 - val_accuracy: 0.8208\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 27s 44ms/step - loss: 0.4091 - accuracy: 0.8170 - val_loss: 0.4034 - val_accuracy: 0.8080\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 31s 49ms/step - loss: 0.3772 - accuracy: 0.8362 - val_loss: 0.3579 - val_accuracy: 0.8440\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 34s 54ms/step - loss: 0.3557 - accuracy: 0.8486 - val_loss: 0.3621 - val_accuracy: 0.8388\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 28s 44ms/step - loss: 0.3313 - accuracy: 0.8602 - val_loss: 0.3193 - val_accuracy: 0.8644\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 28s 44ms/step - loss: 0.3136 - accuracy: 0.8693 - val_loss: 0.3159 - val_accuracy: 0.8672\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.2959 - accuracy: 0.8788 - val_loss: 0.3335 - val_accuracy: 0.8548\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 31s 50ms/step - loss: 0.2829 - accuracy: 0.8853 - val_loss: 0.3277 - val_accuracy: 0.8664\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 27s 44ms/step - loss: 0.2667 - accuracy: 0.8920 - val_loss: 0.3262 - val_accuracy: 0.8704\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78d8055c2a40>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g0-sqbd4jXJ",
        "outputId": "8715951b-065c-4561-8a5f-8174c0dcbdcb"
      },
      "id": "0g0-sqbd4jXJ",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 16s 20ms/step - loss: 0.3368 - accuracy: 0.8658\n",
            "Test acc: 0.866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_0N2V3V4ly5",
        "outputId": "c6fd3996-d042-496b-9213-ac0005e81ba3"
      },
      "id": "v_0N2V3V4ly5",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 100)         2000000   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 64)                34048     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2034113 (7.76 MB)\n",
            "Trainable params: 34113 (133.25 KB)\n",
            "Non-trainable params: 2000000 (7.63 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5pbSLM7o6Yg7"
      },
      "id": "5pbSLM7o6Yg7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}