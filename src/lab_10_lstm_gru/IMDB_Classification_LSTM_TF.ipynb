{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffc3fbbd-fbbb-479b-a252-8f0fc2c6346c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffc3fbbd-fbbb-479b-a252-8f0fc2c6346c",
    "outputId": "f17b43ba-1b69-46b5-d8a3-8f79cde1a3e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('all')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from collections import Counter\n",
    "\n",
    "import os, pathlib, shutil, random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unrX5_rrzHBw",
   "metadata": {
    "id": "unrX5_rrzHBw"
   },
   "source": [
    "## Download IMDB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5155fbb1-f0f2-45c2-ba69-13baae32de7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5155fbb1-f0f2-45c2-ba69-13baae32de7e",
    "outputId": "46831c7f-9371-4119-fd9b-06d9c2babfb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  10.1M      0  0:00:07  0:00:07 --:--:-- 17.2M\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz\n",
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "s1QOJJPlzEuR",
   "metadata": {
    "id": "s1QOJJPlzEuR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfa26e8-8606-49f9-9638-8e34da8f19ef",
   "metadata": {
    "id": "acfa26e8-8606-49f9-9638-8e34da8f19ef"
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "# data = pd.read_csv('data/IMDB Dataset.csv')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee8f3b-02fe-431d-94d0-701f0a93fda3",
   "metadata": {
    "id": "18ee8f3b-02fe-431d-94d0-701f0a93fda3"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228d43fd-e39a-4402-9783-ff41ea9edda2",
   "metadata": {
    "id": "228d43fd-e39a-4402-9783-ff41ea9edda2"
   },
   "source": [
    "### Creating and organizing files in folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb6e04cc-fc13-44a2-8d5f-a9836a046248",
   "metadata": {
    "id": "bb6e04cc-fc13-44a2-8d5f-a9836a046248"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e289f41-5559-49ed-930b-e386d4a6b7f2",
   "metadata": {
    "id": "9e289f41-5559-49ed-930b-e386d4a6b7f2"
   },
   "source": [
    "### Load train, validation and test datasets from folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73656316-4a36-4bbd-8c2d-40357a71a991",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73656316-4a36-4bbd-8c2d-40357a71a991",
    "outputId": "d705d9fe-55c4-4c0a-f644-b003beec9cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "val_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a477b34-8726-40d2-a2b9-43f3b30a57b8",
   "metadata": {
    "id": "3a477b34-8726-40d2-a2b9-43f3b30a57b8"
   },
   "outputs": [],
   "source": [
    "text_only_train_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089c7d01-ee79-4d5f-9a85-a10ae770758d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "089c7d01-ee79-4d5f-9a85-a10ae770758d",
    "outputId": "7240dcca-92f7-4093-df8f-68ed27ca1366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review : tf.Tensor(b\"Kirstie Alley, looking a bit slimmer, but only a bit, is in this mess along with a man who is a MacGuyver lookalike, bleached blond hair and all. The premise of the movie is about an older woman (50!!!) who cannot get her screenplay produced due to age discrimination so she sends in her younger nephew to pose as the writer. Not an original idea and not a very good movie with lousy acting, inane dialogue and a ridiculous plot. There is another plot concerning a writer with a crush or admiration for Kirstie's character and why this is included is a mystery. The actor who portrays Kirstie's brother is so wooden and miscast, it was torture to watch their scenes. What is there to say about this film. Avoid it.\", shape=(), dtype=string)\n",
      "Label:  tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "Review : tf.Tensor(b\"I had a chance to see a screening of this movie recently. I believe that it will be in theaters in Canada some time around Mother's Day. If it is in a theater near you... GO! It's not a funny feel-good movie - it's more along the lines of a feel and think movie.<br /><br />The director does an excellent job of character development - letting you into the heart, mind and hurts of Hagar little by little. At first, her attitudes and behaviors don't make much sense. As her story unfolds, she becomes someone you can understand. As in life... understanding brings empathy. I found her likable by the end of the movie - particularly when she opens up her heart to the young man in the shack by the lake.<br /><br />Hagar's relationship with her two sons is painful - and reflective of so many of our own experiences in this world. Her youngest son, John, who is full of life and adventure takes the viewer to the very edge of their seat - and into the kind of raw emotion that is so authentic and rare.<br /><br />It's fun to see Ellen Page acting in this movie. She is so very different than the young woman that she plays in Juno. It gives me an even broader appreciation for her acting ability. If you loved her in Juno, you'll love her in The Stone Angel.<br /><br />Of course, there is Ellen Burnstyn as Hagar. There is likely no way of expressing the power of acting as strongly as the ability for the actor to make you forget every other character they have ever played. Never once in the course of this movie did I ever think of Ellen Burnstyn - I always and only thought of Hagar. She swept me into her character - hook, line and sinker.<br /><br />Kari Skogland's capacity to capture on film this renowned book by one of Canada's most cherished authors is impressive. She brilliantly brings to the screen both the stoney and angelic parts of this complex woman, Hagar - the stone angel.\", shape=(), dtype=string)\n",
      "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "Review : tf.Tensor(b'Frankly, this movie has gone over the heads of most of its detractors.<br /><br />The opposite of perdition (being lost) is salvation (being saved) and this movie is one of a very few to deal with those two concepts. The movie also explores the love and disappointments that attend the father-son relationship. It should be noted at the outset that none of these are currently fashionable themes.<br /><br />The premise is that the fathers in the move, hit-man Michael Sullivan (Tom Hanks) and his crime boss John Rooney (Paul Newman), love their sons and will do anything to protect them. But Rooney\\'s son Connor is even more evil than the rest. He kills one of Rooney\\'s loyal soldiers to cover up his own stealing from his father. When Connor learns that Sullivan\\'s son Michael witnessed it, he mistakenly kills Sullivan\\'s other son (and Sullivan\\'s wife) in an attempt to silence witnesses.<br /><br />Sullivan decides he wants revenge at any price, even at the terribly high price of perdition. Rooney, who in one scene curses the day Connor was born, refuses to give up his son Connor to Sullivan, and hires a contract killer named Maguire (Jude Law) to kill Sullivan and his son. So Rooney joins his son Connor on the Road to Perdition.<br /><br />For the rest of the movie, accompanied by his surviving son young Michael, Sullivan pursues Connor Rooney down the Road to Perdition, and Maguire pursues Sullivan. When Sullivan confronts Rooney in a Church basement, and demands that he give up Connor because Connor murdered his family, Rooney says - \"Michael, there are only murderers in this room,.., and there\\'s only one guarantee, none of us will see Heaven.\" As the movie ends, somewhat predictably, one character is saved and one character repents.<br /><br />I\\'m not a big Tom Hanks fan, but he does step out of character to play hit-man Sullivan convincingly, giving a subtle and laconic performance. Newman does well as the old Irish gangster Rooney, showing a hard edge in his face and manner, his eyes haunted by Connor\\'s misdeeds. Jude Law plays Maguire in a suitably creepy way. Tyler Hoechlin plays Young Michael naturally and without affectation.<br /><br />The cinematography constantly played light off from darkness, echoing the themes of salvation and perdition. The camera drew from a palette of greens and greys. The greys belonged to the fathers and the urban landscapes of Depression era Illinois. The greens belonged to the younger sons and that State\\'s rural flatlands. Thomas Newman\\'s lush, sonorous and haunting music had faint Irish overtones and was played out in Copland-like arrangements. The sets were authentic mid-Western urban - factories, churches. The homes shone with gleaming woodwork.<br /><br />The excellence of the movie lies in its generation of a unique feeling out of its profound themes, distinctive acting, and enveloping music and cinematography. The only negative was a slight anti-gun message slipped into the screenplay y, the movie\\'s only nod to political correctness.<br /><br />I give this movie a10 out of 10; in time it will be acknowledged as a great film.', shape=(), dtype=string)\n",
      "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "Review : tf.Tensor(b\"The acting in this movie was superb, but mixed with the truth about the condition of many Africans in South Africa made it heart wrenching. It was good that the writer isolated Boesman and Lena from others run from their homes, so we could share fully in their triumphs and defeats; the conflicts they shared as they grew together and apart. Worth seeing when you put the movie in it's proper context.\", shape=(), dtype=string)\n",
      "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "Review : tf.Tensor(b\"Watching this movie is like eating a banquet of nothing but meringue. It initially looks great but ultimately provides NO satisfaction--none.<br /><br />The plot is a muddled mess about a toy factory and the forces of evil. So, how is it possible that with this basic plot AND Robin Williams that the movie still turns out so badly?! It's because the picture is all appearance with no substance whatsoever--much like the terrible Popeye picture Williams did at the beginning of his film career. The film must have cost a fortune but perhaps there wasn't enough money left over to hire writers who had graduated grade school.<br /><br />The film is one unfunny joke that goes on and on and on and on. I really am unsure why it was made in the first place--it certainly wasn't made to provide any sort of entertainment.\", shape=(), dtype=string)\n",
      "Label:  tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "Review : tf.Tensor(b\"I can't believe I wasted my time with this movie. I couldn't even call it a movie. It was so bad with nothing to recommend it. <br /><br />I like low budget movies and weird flicks but this one had me bored to death. Badly made and bad acting ruined it from being curious. You have to wonder what these people were thinking when they spent money to produce this movie. I wonder what I was thinking watching it to the end. I recommend this movie to no one. How did they release this? Was there an audience who likes this kind of movie? There must be because you can find this at almost any video store. But why?<br /><br />Deserves to be forgotten.<br /><br />If you like bad movies then this is for you.\", shape=(), dtype=string)\n",
      "Label:  tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x, y in train_ds:\n",
    "    for text, label in zip(x,y):\n",
    "        counter += 1\n",
    "        print(\"Review :\", text)\n",
    "        print(\"Label: \", label)\n",
    "        print(\"\\n\")\n",
    "        if counter > 5:\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db06fdce-e9c2-46bc-97fd-057e792975d7",
   "metadata": {
    "id": "db06fdce-e9c2-46bc-97fd-057e792975d7"
   },
   "source": [
    "### Convert text data into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c5a5a1-4412-4e9b-b0bb-cd99ec610991",
   "metadata": {
    "id": "03c5a5a1-4412-4e9b-b0bb-cd99ec610991"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "int_train_ds = train_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(lambda x, y: (text_vectorization(x), y), num_parallel_calls=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9d3a9a-0ac8-4d1b-91af-2a0ddac402d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e9d3a9a-0ac8-4d1b-91af-2a0ddac402d3",
    "outputId": "74763fb1-5ee4-49f9-bc76-20dc526eb6b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review : tf.Tensor(\n",
      "[   11    18    14   641    33  2539  7030    38    23   118    12     2\n",
      "   873   152    26    73   285     6   162  5097    13   254    47   719\n",
      "   196   724     2  9553     8    11    18    80     5     2    51   762\n",
      "  2331   460   592  4835  1416    49    24   933  3866    43    11   702\n",
      "    13  4287    15   246    33     2   524  1046     1     1     7     4\n",
      "  1257   109    47    83    39   127    93  5122    80     2   565    69\n",
      "   294  1424    19   131     2     1     5   496  2628  3262    16     8\n",
      "     4   811    19 10090  1358    24    48  3137     2 15947     5  4287\n",
      "  1151  4287 11083   756    31     2   130    16    34   503     5   115\n",
      "   113    87     5   127    93   473    79     2   762    32    46   546\n",
      "     6     2   343     3     2   426   109  1446    41    15   426     8\n",
      "     2   130    15     6   885  5097    13    47  2720  8992     8    11\n",
      "   438    19    10    26     6   194     9  1102    46     5   295   391\n",
      "   450    21    30     1     3   409  2793    15  1034     6     2   622\n",
      "   259    21     4   433     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0], shape=(600,), dtype=int64)\n",
      "Label:  tf.Tensor(1, shape=(), dtype=int32)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for x, y in int_train_ds:\n",
    "    for text, label in zip(x,y):\n",
    "        counter += 1\n",
    "        print(\"Review :\", text)\n",
    "        print(\"Label: \", label)\n",
    "        print(\"\\n\")\n",
    "        if counter >= 1:\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9accb3f-26a1-4938-8b63-accb12eb0121",
   "metadata": {
    "id": "d9accb3f-26a1-4938-8b63-accb12eb0121"
   },
   "source": [
    "### A sequence model built on one-hot encoded vector sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e270f4f8-e78f-415e-bdde-7dbcb5e76aac",
   "metadata": {
    "id": "e270f4f8-e78f-415e-bdde-7dbcb5e76aac"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Lambda(lambda x: tf.one_hot(x, depth=max_tokens)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e7295d-fb66-474f-94d8-c33b62d851dc",
   "metadata": {
    "id": "d8e7295d-fb66-474f-94d8-c33b62d851dc"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e80d0a8-a932-41c5-890d-fc052d22cbab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e80d0a8-a932-41c5-890d-fc052d22cbab",
    "outputId": "2eb73c46-f529-4788-f453-370b48288819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 422s 659ms/step - loss: 0.6223 - accuracy: 0.6621 - val_loss: 0.4413 - val_accuracy: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79089f973760>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "STCRTt2Szvdx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STCRTt2Szvdx",
    "outputId": "901a81c9-19f5-4103-ca6b-70c917c90342"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 600, 20000)        0         \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 256)               20612096  \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20612353 (78.63 MB)\n",
      "Trainable params: 20612353 (78.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dhd8BZEWmwQ",
   "metadata": {
    "id": "8dhd8BZEWmwQ"
   },
   "outputs": [],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa9c63c-fa84-49f6-942d-bcf4eed5d70f",
   "metadata": {
    "id": "6aa9c63c-fa84-49f6-942d-bcf4eed5d70f"
   },
   "outputs": [],
   "source": [
    "## Try with embedding layer instead of one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "kwl7N1SXy9br",
   "metadata": {
    "id": "kwl7N1SXy9br"
   },
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apRNR2uo0l5I",
   "metadata": {
    "id": "apRNR2uo0l5I"
   },
   "source": [
    "### Build Model (Embedding from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "L5VEjuU-ztSd",
   "metadata": {
    "id": "L5VEjuU-ztSd"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=max_tokens, output_dim=256, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7urzO2MG0od_",
   "metadata": {
    "id": "7urzO2MG0od_"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8Lzaw4ac04Tb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Lzaw4ac04Tb",
    "outputId": "ffa6d0e9-fd99-4665-d226-b4a967721e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 112s 167ms/step - loss: 0.4618 - accuracy: 0.7760 - val_loss: 0.3319 - val_accuracy: 0.8640\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.2956 - accuracy: 0.8848 - val_loss: 0.3261 - val_accuracy: 0.8712\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 51s 82ms/step - loss: 0.2311 - accuracy: 0.9112 - val_loss: 0.3639 - val_accuracy: 0.8382\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 46s 74ms/step - loss: 0.1872 - accuracy: 0.9306 - val_loss: 0.3133 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 45s 72ms/step - loss: 0.1442 - accuracy: 0.9484 - val_loss: 0.3742 - val_accuracy: 0.8662\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.1055 - accuracy: 0.9640 - val_loss: 0.4126 - val_accuracy: 0.8610\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 42s 67ms/step - loss: 0.0808 - accuracy: 0.9721 - val_loss: 0.4310 - val_accuracy: 0.8494\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 40s 63ms/step - loss: 0.0573 - accuracy: 0.9803 - val_loss: 0.5044 - val_accuracy: 0.8668\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.0429 - accuracy: 0.9858 - val_loss: 0.5342 - val_accuracy: 0.8648\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 40s 64ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.5803 - val_accuracy: 0.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7908817c9ea0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "JwCxx1V25PPB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwCxx1V25PPB",
    "outputId": "4313e91e-15f3-4478-cc2d-a730bce6e9b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 18s 23ms/step - loss: 0.6267 - accuracy: 0.8506\n",
      "Test acc: 0.851\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "IC8qIBtUIkdZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IC8qIBtUIkdZ",
    "outputId": "4a958b34-ec07-4d8a-d248-e698cdad09e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 256)               394240    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5514497 (21.04 MB)\n",
      "Trainable params: 5514497 (21.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PRfqwRaL2iKf",
   "metadata": {
    "id": "PRfqwRaL2iKf"
   },
   "source": [
    "### Use pretrained embedding instead of building from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9V75JV1S3Ydf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9V75JV1S3Ydf",
    "outputId": "2960bdc3-5c65-41bf-89e8-4af972aae938"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-10 08:28:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-09-10 08:28:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-09-10 08:28:26--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.10MB/s    in 2m 40s  \n",
      "\n",
      "2023-09-10 08:31:06 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7TuR42M807fX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7TuR42M807fX",
    "outputId": "81b03134-be30-4195-9c70-2a1076cb55ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"Found {len(embeddings_index)} word vectors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GnbR3Gcs2rkQ",
   "metadata": {
    "id": "GnbR3Gcs2rkQ"
   },
   "source": [
    "### prepare Glove word Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "Lj3aXPO_2wSd",
   "metadata": {
    "id": "Lj3aXPO_2wSd"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
    "\n",
    "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < max_tokens:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "kF-bs3xh25eX",
   "metadata": {
    "id": "kF-bs3xh25eX"
   },
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    max_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    "    mask_zero=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "un2iDsTF3H-Q",
   "metadata": {
    "id": "un2iDsTF3H-Q"
   },
   "source": [
    "## Build Model with pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "rlEmh2Mq3HRK",
   "metadata": {
    "id": "rlEmh2Mq3HRK"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8251e648-bc6d-40c7-bdcb-e253f0b79a2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1506051000.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    tf.keras.layers.\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b3rBL-44W4Q",
   "metadata": {
    "id": "0b3rBL-44W4Q"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "gnt8FEoW4bXO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gnt8FEoW4bXO",
    "outputId": "2a777ac0-99b6-4328-9ca3-f74779be5782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 49s 65ms/step - loss: 0.5703 - accuracy: 0.7012 - val_loss: 0.4755 - val_accuracy: 0.7816\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 37s 60ms/step - loss: 0.4465 - accuracy: 0.7948 - val_loss: 0.3923 - val_accuracy: 0.8252\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 36s 57ms/step - loss: 0.3879 - accuracy: 0.8286 - val_loss: 0.3613 - val_accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.3444 - accuracy: 0.8526 - val_loss: 0.3232 - val_accuracy: 0.8638\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.3130 - accuracy: 0.8676 - val_loss: 0.3136 - val_accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.2899 - accuracy: 0.8787 - val_loss: 0.3161 - val_accuracy: 0.8754\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 35s 57ms/step - loss: 0.2670 - accuracy: 0.8911 - val_loss: 0.3184 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 34s 55ms/step - loss: 0.2450 - accuracy: 0.9035 - val_loss: 0.3044 - val_accuracy: 0.8770\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 33s 53ms/step - loss: 0.2225 - accuracy: 0.9133 - val_loss: 0.3158 - val_accuracy: 0.8768\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 34s 54ms/step - loss: 0.2019 - accuracy: 0.9212 - val_loss: 0.3277 - val_accuracy: 0.8804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x79080a2934c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0g0-sqbd4jXJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0g0-sqbd4jXJ",
    "outputId": "5546eaf9-48c6-4bf3-cec9-a6a70af4f3e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 19s 24ms/step - loss: 0.3272 - accuracy: 0.8756\n",
      "Test acc: 0.876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "v_0N2V3V4ly5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_0N2V3V4ly5",
    "outputId": "d8ac9613-31bb-445d-8dee-d4b90352fc87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, None, 100)         2000000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 256)               234496    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2234753 (8.52 MB)\n",
      "Trainable params: 234753 (917.00 KB)\n",
      "Non-trainable params: 2000000 (7.63 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5pbSLM7o6Yg7",
   "metadata": {
    "id": "5pbSLM7o6Yg7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
